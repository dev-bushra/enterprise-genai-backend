# ๐ฆ app/services/openai_generator.py
# ุงูููู ูุฐุง ูุณุคูู ุนู:
# ุฅุฑุณุงู prompt_text ูู OpenAI.
# ุงุณุชูุงู response_text ูู ุงูููุฏูู.
# ุญุณุงุจ ุงูุฒูู ุงููุณุชุบุฑู

# ๐ ุงููุณุงุฑ: app/services/openai_generator.py

# ๐ง ูุฐุง ุงูููู ูุณุคูู ุนู:
# - ุงูุงุชุตุงู ุจููุชุจุฉ OpenAI ูุชูููุฏ ุงูุฑุฏูุฏ ุงูุฐููุฉ.
# - ุฅุฑุณุงู prompt ุฅูู API ูุงุณุชุฑุฌุงุน ุงูุฑุฏ ูุน ุญุณุงุจ ุงูุฒูู.
# - ููุณุชุฎุฏู ุฏุงุฎู ุงูุฎุฏูุงุช ุงูุชู ุชุญุชุงุฌ ุฅูู ุชูููุฏ ูุญุชูู ุขูู ุจุงุณุชุฎุฏุงู ุงูุฐูุงุก ุงูุงุตุทูุงุนู.


import openai  # ููุชุจุฉ OpenAI ููุชุนุงูู ูุน ููุงุฐุฌ ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูุซู GPT
import time  # ูุญุณุงุจ ุงูุฒูู ุงููุณุชุบุฑู ูู ุงูุชูููุฏ
import os  # ูููุตูู ุฅูู ูุชุบูุฑุงุช ุงูุจูุฆุฉ
from dotenv import load_dotenv  # ูุชุญููู ูุชุบูุฑุงุช ุงูุจูุฆุฉ ูู ููู .env

load_dotenv()  # ุชุญููู ุงููุชุบูุฑุงุช ูู ููู .env ุชููุงุฆููุง

# ๐ ุฅุนุฏุงุฏ ููุชุงุญ OpenAI API ูู ูุชุบูุฑุงุช ุงูุจูุฆุฉ
openai.api_key = os.getenv("OPENAI_API_KEY")  # ุชุนููู ุงูููุชุงุญ ุงูุณุฑู ูุงุณุชุฎุฏุงู API


# ุชุฑุณู ูุต ุงูู prompt ุฅูู OpenAI ูุชุนูุฏ ุงูุฑุฏ ุงูุฌุงูุฒ ูุน ุงูููุช ุงููุณุชุบุฑู ุจุงููููู ุซุงููุฉ.
# Generate AI Response : this method do?
def generate_ai_response(
    prompt_text: str, model: str = "gpt-3.5-turbo"
):  # ุฏุงูุฉ ูุชูููุฏ ุฑุฏ ูู ุงูุฐูุงุก ุงูุงุตุทูุงุนู ุจุงุณุชุฎุฏุงู prompt ูุนูู
    start_time = time.time()  # ุจุฏุก ุนุฏุงุฏ ุงูููุช ูุญุณุงุจ ุงููุฏุฉ ุงููุณุชุบุฑูุฉ

    try:
        response = openai.ChatCompletion.create(  # ุงุณุชุฏุนุงุก ูุงุฌูุฉ OpenAI ูุชูููุฏ ุงูุฑุฏ ูู ุงููููุฐุฌ ุงููุฎุชุงุฑ
            model=model,  # ุชุญุฏูุฏ ุงููููุฐุฌ (ูุซู gpt-3.5-turbo)
            messages=[
                {
                    "role": "user",
                    "content": prompt_text,
                }  # ุฅุฑุณุงู prompt ุจุตูุบุฉ ุฑุณุงูุฉ ูุณุชุฎุฏู
            ],
            temperature=0.7,  # ุฏุฑุฌุฉ ุงูุนุดูุงุฆูุฉ ูู ุงูุฑุฏ
            max_tokens=1000,  # ุงูุญุฏ ุงูุฃูุตู ูุนุฏุฏ ุงููููุงุช ูู ุงูุฑุฏ
        )

        reply = response.choices[0].message.content  # ุงุณุชุฎุฑุงุฌ ุงููุต ุงููุงุชุฌ ูู ุงูุฑุฏ
        duration = int((time.time() - start_time) * 1000)  # ุญุณุงุจ ุงููุฏุฉ ุจุงููููู ุซุงููุฉ

        return {
            "response_text": reply,  # ูุต ุงูุฑุฏ ุงูููุงุฆู ูู ุงูุฐูุงุก ุงูุงุตุทูุงุนู
            "duration_ms": duration,  # ุงููุฏุฉ ุงููุณุชุบุฑูุฉ ูู ุชูููุฏ ุงูุฑุฏ
        }

    except Exception as e:
        raise RuntimeError(
            f"OpenAI generation failed: {str(e)}"
        )  # ูู ุญุงู ุญุฏูุซ ุฎุทุฃุ ูุฑูุน ุงุณุชุซูุงุก ูุฎุตุต ุจุฑุณุงูุฉ ูุงุถุญุฉ


"""


๐ฆ generate_ai_response(prompt_text: str, model: str = "gpt-3.5-turbo")
โ ุงููุธููุฉ:



๐ง ุงูุดุฑุญ ุณุทุฑ ุจุณุทุฑ:
python
Copy
Edit
start_time = time.time()
๐น ูุจุฏุฃ ุนุฏุงุฏ ุงูููุช ูุญุณุงุจ ุงูุฒูู ุงููุณุชุบุฑู ูู ุงูุชูููุฏ.

python
Copy
Edit
response = openai.ChatCompletion.create(
    model=model,
    messages=[
        {
            "role": "user",
            "content": prompt_text,
        }
    ],
    temperature=0.7,
    max_tokens=1000,
)
๐น ูุฐุง ูู ุงูุงุณุชุฏุนุงุก ุงูุฑุฆูุณู ูููุชุจุฉ OpenAI:

model: ุงุณู ุงูููุฏูู ูุซู "gpt-3.5-turbo" ุฃู "gpt-4".

messages: ูุงุฆูุฉ ุงููุญุงุฏุซุฉุ ููุฑุณู ููุท ุฑุณุงูุฉ ูุงุญุฏุฉ ูู ุงูููุน "user".

temperature: ุฏุฑุฌุฉ ุงูุฅุจุฏุงุน ูุงูุนุดูุงุฆูุฉ (0 = ุซุงุจุชุ 1 = ุฃูุซุฑ ุชููุน).

max_tokens: ุนุฏุฏ ุงููููุงุช ุฃู ุงูุฑููุฒ ุงููุตูู ูู ุงูุฑุฏ.

python
Copy
Edit
reply = response.choices[0].message.content
๐น ุงุณุชุฎุฑุงุฌ ุงูุฑุฏ ุงูููุงุฆู ูู ูุชูุฌุฉ OpenAI. ุงูุฑุฏ ูููู ูู choices[0].message.content.

python
Copy
Edit
duration = int((time.time() - start_time) * 1000)
๐น ูุญุณุจ ุงููุฏุฉ ุงูุฒูููุฉ ุจุงููููู ุซุงููุฉ ููุฐ ุจุฏุงูุฉ ุงูุชุดุบูู.

python
Copy
Edit
return {
    "response_text": reply,
    "duration_ms": duration,
}
๐น ููุนูุฏ ุงูุฑุฏ ูู ูุงููุณ ูุญุชูู ุนูู:

response_text: ุงูุฑุฏ ูู OpenAI.

duration_ms: ุงูุฒูู ุงููุณุชุบุฑู ูู ุชูููุฏ ุงูุฑุฏ.

python
Copy
Edit
except Exception as e:
    raise RuntimeError(f"OpenAI generation failed: {str(e)}")
๐บ ุฅุฐุง ุญุตู ุฃู ุฎุทุฃ (ูุซูุงู API key ูุงูุต ุฃู timeout)ุ ูุชู ุฑูุน ุงุณุชุซูุงุก ูุฎุตุต ุจุฑุณุงูุฉ ูุงุถุญุฉ ูููุทูุฑ.

โ ูุซุงู ุนูู ุงูุงุณุชุฎุฏุงู:
python
Copy
Edit
result = generate_ai_response("ุงุดุฑุญ ูู ุงูุฐูุงุก ุงูุงุตุทูุงุนู", "gpt-4")
print(result)
๐งพ ุงููุงุชุฌ ุงููุชููุน:

json
Copy
Edit
{
  "response_text": "ุงูุฐูุงุก ุงูุงุตุทูุงุนู ูู...",
  "duration_ms": 812
}


๐ฆ ุชูุฎูุต ุณุฑูุน:
ุงูุฎุงุตูุฉ	ูุนูุงูุง
prompt_text	ุงููุต ุงููุทููุจ ุฅุฑุณุงูู ูู OpenAI
model	ุงุณู ุงููููุฐุฌ (ุงูุชุฑุงุถู gpt-3.5-turbo)
response_text	ุงูุฑุฏ ุงููุงุชุฌ ูู ุงูุฐูุงุก ุงูุงุตุทูุงุนู
duration_ms	ุงูุฒูู ุงููุณุชุบุฑู ุจุงูุชูููุฏ (ms)
ุงูุชุนุงูู ูุน ุงูุฃุฎุทุงุก	ูุชู ุฑูุน RuntimeError ุจุฑุณุงูุฉ ูููููุฉ


 """
